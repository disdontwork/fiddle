<!DOCTYPE html>
<html>
<head>
    <title>Realtime Webcam Displacement</title>
    <style>
        body { margin: 0; overflow: hidden; }
        #controls {
            position: fixed;
            top: 10px;
            left: 10px;
            background: rgba(0,0,0,0.7);
            padding: 10px;
            color: white;
            font-family: Arial;
            z-index: 100;
        }
        #debugCanvas {
            position: fixed;
            top: 10px;
            right: 10px;
            width: 160px;
            height: 120px;
            border: 2px solid white;
            z-index: 100;
        }
        #video {
            position: fixed;
            top: -9999px;
            left: -9999px;
        }
    </style>
</head>
<body>
    <div id="controls">
        <button id="startCamera">Start Camera</button>
        <br><br>
        Displacement: <input type="range" id="displacementScale" min="0" max="2" step="0.1" value="0.5">
        <br>
        Segments: <input type="range" id="segments" min="1" max="256" step="1" value="64">
    </div>
    
    <video id="video" autoplay playsinline></video>
    <canvas id="debugCanvas"></canvas>

    <script type="module">
        import * as THREE from 'https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.module.js';
        
        // Setup debug canvas for processing
        const debugCanvas = document.getElementById('debugCanvas');
        const debugCtx = debugCanvas.getContext('2d');
        debugCanvas.width = 256;
        debugCanvas.height = 256;

        // Setup video
        const video = document.getElementById('video');
        let videoTexture;
        let isVideoPlaying = false;

        // Three.js setup
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Create material and plane
        const material = new THREE.MeshPhongMaterial({
            color: 0x808080,
            displacementScale: 0.5,
            side: THREE.DoubleSide,
        });

        let plane = new THREE.Mesh(
            new THREE.PlaneGeometry(5, 5, 64, 64),
            material
        );
        scene.add(plane);

        // Lighting
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(1, 1, 1);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0x404040));

        camera.position.z = 5;

        // Camera button handler
        document.getElementById('startCamera').addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: 640,
                        height: 480
                    }
                });
                
                video.srcObject = stream;
                await video.play();
                
                // Create video texture once video is playing
                videoTexture = new THREE.Texture(debugCanvas);
                material.displacementMap = videoTexture;
                isVideoPlaying = true;
                
            } catch (error) {
                console.error('Error accessing camera:', error);
                alert('Unable to access camera. Please ensure you have a camera connected and have granted permission.');
            }
        });

        // Process video to grayscale
        function processVideo() {
            if (!isVideoPlaying) return;
            
            debugCtx.drawImage(video, 0, 0, debugCanvas.width, debugCanvas.height);
            const imageData = debugCtx.getImageData(0, 0, debugCanvas.width, debugCanvas.height);
            const data = imageData.data;

            for (let i = 0; i < data.length; i += 4) {
                const grayscale = (data[i] * 0.299 + data[i + 1] * 0.587 + data[i + 2] * 0.114) / 255;
                data[i] = data[i + 1] = data[i + 2] = grayscale * 255;
            }

            debugCtx.putImageData(imageData, 0, 0);
            if (videoTexture) videoTexture.needsUpdate = true;
        }

        // Controls
        document.getElementById('displacementScale').addEventListener('input', (e) => {
            material.displacementScale = parseFloat(e.target.value);
        });

        document.getElementById('segments').addEventListener('input', (e) => {
            const segments = parseInt(e.target.value);
            scene.remove(plane);
            plane = new THREE.Mesh(
                new THREE.PlaneGeometry(5, 5, segments, segments),
                material
            );
            scene.add(plane);
        });

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            if (isVideoPlaying) {
                processVideo();
            }
            plane.rotation.x = Math.PI / 4;
            plane.rotation.y += 0.01;
            renderer.render(scene, camera);
        }

        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        animate();
    </script>
</body>
</html>
